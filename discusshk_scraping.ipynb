{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5c95a57-9681-401a-b226-fd0fd3f5d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "615b3fc6-a01f-4767-b1b7-6be15e62239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 103.0.5060\n",
      "Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "Driver [/Users/kayuenko/.wdm/drivers/chromedriver/mac64_m1/103.0.5060.53/chromedriver] found in cache\n",
      "/var/folders/ms/wg96lht949l8mqzyvc10vtv80000gn/T/ipykernel_45530/2673790649.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.53)\nStacktrace:\n0   chromedriver                        0x0000000104651d14 chromedriver + 3792148\n1   chromedriver                        0x00000001045e8828 chromedriver + 3360808\n2   chromedriver                        0x00000001042e90b8 chromedriver + 217272\n3   chromedriver                        0x00000001042d8124 chromedriver + 147748\n4   chromedriver                        0x00000001042d78f4 chromedriver + 145652\n5   chromedriver                        0x00000001042d6f50 chromedriver + 143184\n6   chromedriver                        0x00000001042d67f8 chromedriver + 141304\n7   chromedriver                        0x00000001042ef69c chromedriver + 243356\n8   chromedriver                        0x0000000104341d74 chromedriver + 580980\n9   chromedriver                        0x000000010430e318 chromedriver + 369432\n10  chromedriver                        0x00000001046271e8 chromedriver + 3617256\n11  chromedriver                        0x000000010462b678 chromedriver + 3634808\n12  chromedriver                        0x000000010462fc6c chromedriver + 3652716\n13  chromedriver                        0x000000010462c110 chromedriver + 3637520\n14  chromedriver                        0x000000010460a7ac chromedriver + 3499948\n15  chromedriver                        0x0000000104643bf0 chromedriver + 3734512\n16  chromedriver                        0x0000000104643d54 chromedriver + 3734868\n17  chromedriver                        0x0000000104658558 chromedriver + 3818840\n18  libsystem_pthread.dylib             0x0000000186159240 _pthread_start + 148\n19  libsystem_pthread.dylib             0x0000000186154024 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     79\u001b[0m url2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&page=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 80\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(driver\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m all_comments \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostmessage-content t_msgfont\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kayuenko-kYldoSgF/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:437\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kayuenko-kYldoSgF/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:425\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    423\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[1;32m    427\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/kayuenko-kYldoSgF/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    245\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.53)\nStacktrace:\n0   chromedriver                        0x0000000104651d14 chromedriver + 3792148\n1   chromedriver                        0x00000001045e8828 chromedriver + 3360808\n2   chromedriver                        0x00000001042e90b8 chromedriver + 217272\n3   chromedriver                        0x00000001042d8124 chromedriver + 147748\n4   chromedriver                        0x00000001042d78f4 chromedriver + 145652\n5   chromedriver                        0x00000001042d6f50 chromedriver + 143184\n6   chromedriver                        0x00000001042d67f8 chromedriver + 141304\n7   chromedriver                        0x00000001042ef69c chromedriver + 243356\n8   chromedriver                        0x0000000104341d74 chromedriver + 580980\n9   chromedriver                        0x000000010430e318 chromedriver + 369432\n10  chromedriver                        0x00000001046271e8 chromedriver + 3617256\n11  chromedriver                        0x000000010462b678 chromedriver + 3634808\n12  chromedriver                        0x000000010462fc6c chromedriver + 3652716\n13  chromedriver                        0x000000010462c110 chromedriver + 3637520\n14  chromedriver                        0x000000010460a7ac chromedriver + 3499948\n15  chromedriver                        0x0000000104643bf0 chromedriver + 3734512\n16  chromedriver                        0x0000000104643d54 chromedriver + 3734868\n17  chromedriver                        0x0000000104658558 chromedriver + 3818840\n18  libsystem_pthread.dylib             0x0000000186159240 _pthread_start + 148\n19  libsystem_pthread.dylib             0x0000000186154024 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options) \n",
    "driver.implicitly_wait(0.5)\n",
    "link = \"https://finance.discuss.com.hk/forumdisplay.php?fid=57&filter=type&orderby=new_lastpost&ascdesc=DESC&typeid=1293\"\n",
    "driver.get(link)\n",
    "time.sleep(2.5)\n",
    "\n",
    "data = {\"Date\":[], \"Comments\":[]}\n",
    "\n",
    "for p in range(1, 5):\n",
    "    if p > 0:\n",
    "        link1 = f\"{link}&page={p}\"\n",
    "        driver.get(link1)\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        all_post = soup.find_all(lambda tag: tag.name == 'tbody' and tag.get('class') == ['forumdisplay_thread'])\n",
    "        # all_post = soup.find_all(\"tbody\", attrs={\"class\":\"forumdisplay_thread\"})\n",
    "\n",
    "        for h in all_post:\n",
    "            url = f\"https://finance.discuss.com.hk/{h.span.a.get('href')}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            ads_elems = driver.find_elements(By.CSS_SELECTOR, \".adsbygoogle.adsbygoogle-noablate[data-vignette-loaded=true]\")\n",
    "            if len(ads_elems) > 0:\n",
    "                ActionChains(driver).move_by_offset(5, 5).click().perform()\n",
    "                time.sleep(5)\n",
    "\n",
    "            # login_elems = driver.find_elements(By.CSS_SELECTOR, \".maintable.wrap.discuss_regist_wapper login.discuss_regist_section\")\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            login_elems = soup.find(\"div\", attrs={\"class\":\"discuss_regist_section\"})\n",
    "            if login_elems != None:\n",
    "                pass\n",
    "                # driver.find_elements(By.CSS_SELECTOR, \".discuss_regist_section form input[name='username']\")[0].send_keys(ID)\n",
    "                # driver.find_elements(By.CSS_SELECTOR, \".discuss_regist_section form input[name='password']\")[0].send_keys(password)\n",
    "                # driver.find_elements(By.CSS_SELECTOR, \".discuss_regist_section form button[name='loginsubmit']\")[0].click()\n",
    "            else:\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                head_comment = soup.find(\"meta\", {\"property\":\"og:description\"})[\"content\"]\n",
    "                head_date = soup.find(\"div\", attrs={\"class\":\"post-date\"}).text\n",
    "                data[\"Date\"].append(head_date)\n",
    "                data[\"Comments\"].append(head_comment)\n",
    "                all_comments = soup.find(\"div\", attrs={\"class\":\"mainbox-container mb-t_msgfont\"}).find_all(\"div\", attrs={\"class\":\"mainbox viewthread\"})\n",
    "\n",
    "                for c in all_comments:\n",
    "                    if c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\") == None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\").find(\"div\", attrs={\"class\":\"quote\"}) != None:\n",
    "                            normal_comments = c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\")\n",
    "                            unwanted = normal_comments.find(\"div\", attrs={\"class\":\"quote\"})\n",
    "                            unwanted.extract()\n",
    "                            comment_date = c.find(\"div\", attrs={\"class\":\"post-date\"}).text\n",
    "                            data[\"Date\"].append(comment_date)\n",
    "                            data[\"Comments\"].append(normal_comments.text)\n",
    "                        elif c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\").find(\"div\", attrs={\"class\":\"quote\"}) == None:\n",
    "                            normal_comments = c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\").text\n",
    "                            comment_date = c.find(\"div\", attrs={\"class\":\"post-date\"}).text\n",
    "                            data[\"Date\"].append(comment_date)\n",
    "                            data[\"Comments\"].append(normal_comments)\n",
    "\n",
    "                exist_pages = soup.find(\"div\", attrs={\"class\":\"pagination-buttons\"})\n",
    "                \n",
    "                driver.switch_to.default_content()\n",
    "\n",
    "                if exist_pages == None:\n",
    "                    pass\n",
    "                else:\n",
    "                    no_pages = math.ceil((int(soup.find(\"div\", attrs={\"class\":\"pagination-buttons\"}).find(\"em\").text))/15)\n",
    "                    for i in range(no_pages+1):\n",
    "                        if i > 1:\n",
    "                            # ads_elems = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, '.adsbygoogle.adsbygoogle-noablate[data-vignette-loaded=true]')))\n",
    "                            ads_elems = driver.find_elements(By.CSS_SELECTOR, \".adsbygoogle.adsbygoogle-noablate[data-vignette-loaded=true]\")\n",
    "                            if len(ads_elems) > 0:\n",
    "                                ActionChains(driver).move_by_offset(5, 5).click().perform()\n",
    "                                time.sleep(5)\n",
    "                            url2 = f'{url}&page={i}'\n",
    "                            driver.get(url2)\n",
    "                            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                            all_comments = soup.find_all(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"})\n",
    "                            comment_date = soup.find_all(\"div\", attrs={\"class\":\"post-date\"})\n",
    "                            for c in all_comments:\n",
    "                                if c.find(\"span\") == None:\n",
    "                                    data[\"Comments\"].append(\"NA\")\n",
    "                                elif c.find(\"span\").find(\"div\", attrs={\"class\":\"quote\"}) != None:\n",
    "                                    comment = c.find(\"span\")\n",
    "                                    unwanted = comment.find(\"div\", attrs={\"class\":\"quote\"})\n",
    "                                    unwanted.extract()\n",
    "                                    data[\"Comments\"].append(comment.text)\n",
    "                                elif c.find(\"span\").find(\"div\", attrs={\"class\": \"quote\"}) == None:\n",
    "                                    comment = c.find(\"span\").text\n",
    "                                    data[\"Comments\"].append(comment)\n",
    "                            for d in comment_date:\n",
    "                                data[\"Date\"].append(d.text)\n",
    "                                \n",
    "                            driver.switch_to.default_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2954424-a1b4-4a05-ad49-bfc80665aed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://finance.discuss.com.hk/forumdisplay.php?fid=57&filter=type&orderby=new_lastpost&ascdesc=DESC&typeid=1293\"\n",
    "\n",
    "data = {\"Date\":[], \"Topic\":[], \"Comments\":[]}\n",
    "\n",
    "for p in range(1, 6):\n",
    "    if p > 0:\n",
    "        link1 = f\"{link}&page={p}\"\n",
    "        page = requests.get(link1)\n",
    "        \n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        all_post = soup.find_all(lambda tag: tag.name == 'tbody' and tag.get('class') == ['forumdisplay_thread'])\n",
    "        # all_post = soup.find_all(\"tbody\", attrs={\"class\":\"forumdisplay_thread\"})\n",
    "\n",
    "        for h in all_post:\n",
    "            url = f\"https://finance.discuss.com.hk/{h.span.a.get('href')}\"\n",
    "            page = requests.get(url)\n",
    "\n",
    "            # ads_elems = driver.find_elements(By.CSS_SELECTOR, \".adsbygoogle.adsbygoogle-noablate[data-vignette-loaded=true]\")\n",
    "            # if len(ads_elems) > 0:\n",
    "            #     ActionChains(driver).move_by_offset(5, 5).click().perform()\n",
    "            #     time.sleep(5)\n",
    "\n",
    "            # login_elems = driver.find_elements(By.CSS_SELECTOR, \".maintable.wrap.discuss_regist_wapper login.discuss_regist_section\")\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "            login_elems = soup.find(\"div\", attrs={\"class\":\"discuss_regist_section\"})\n",
    "            if login_elems != None:\n",
    "                pass\n",
    "                # driver.find_elements(By.CSS_SELECTOR, \".discuss_regist_section form input[name='username']\")[0].send_keys(ID)\n",
    "                # driver.find_elements(By.CSS_SELECTOR, \".discuss_regist_section form input[name='password']\")[0].send_keys(password)\n",
    "                # driver.find_elements(By.CSS_SELECTOR, \".discuss_regist_section form button[name='loginsubmit']\")[0].click()\n",
    "            else:\n",
    "                # soup = BeautifulSoup(page.text, 'html.parser')\n",
    "                head_comment = soup.find(\"meta\", {\"property\":\"og:description\"})[\"content\"]\n",
    "                head_date = soup.find(\"div\", attrs={\"class\":\"post-date\"}).text\n",
    "                Topic_title = soup.find(\"span\", attrs={\"class\":\"topbar_tid\"}).text\n",
    "                data[\"Date\"].append(head_date)\n",
    "                data[\"Topic\"].append(Topic_title)\n",
    "                data[\"Comments\"].append(head_comment)\n",
    "                all_comments = soup.find_all(\"div\", attrs={\"class\":\"mainbox viewthread\"})\n",
    "\n",
    "                for c in all_comments:\n",
    "                    if c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\") == None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\").find(\"div\", attrs={\"class\":\"quote\"}) != None:\n",
    "                            normal_comments = c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\")\n",
    "                            unwanted = normal_comments.find(\"div\", attrs={\"class\":\"quote\"})\n",
    "                            unwanted.extract()\n",
    "                            comment_date = c.find(\"div\", attrs={\"class\":\"post-date\"}).text\n",
    "                            Topic_title = soup.find(\"span\", attrs={\"class\":\"topbar_tid\"}).text\n",
    "                            data[\"Date\"].append(comment_date)\n",
    "                            data[\"Topic\"].append(Topic_title)\n",
    "                            data[\"Comments\"].append(normal_comments.text)\n",
    "                        elif c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\").find(\"div\", attrs={\"class\":\"quote\"}) == None:\n",
    "                            normal_comments = c.find(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"}).find(\"span\").text\n",
    "                            comment_date = c.find(\"div\", attrs={\"class\":\"post-date\"}).text\n",
    "                            Topic_title = soup.find(\"span\", attrs={\"class\":\"topbar_tid\"}).text\n",
    "                            data[\"Date\"].append(comment_date)\n",
    "                            data[\"Topic\"].append(Topic_title)\n",
    "                            data[\"Comments\"].append(normal_comments)\n",
    "\n",
    "                exist_pages = soup.find(\"div\", attrs={\"class\":\"pagination-buttons\"})\n",
    "\n",
    "                if exist_pages == None:\n",
    "                    pass\n",
    "                else:\n",
    "                    no_pages = math.ceil((int(soup.find(\"div\", attrs={\"class\":\"pagination-buttons\"}).find(\"em\").text))/15)\n",
    "                    for i in range(no_pages+1):\n",
    "                        if i > 1:\n",
    "                            # ads_elems = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, '.adsbygoogle.adsbygoogle-noablate[data-vignette-loaded=true]')))\n",
    "                            # ads_elems = driver.find_elements(By.CSS_SELECTOR, \".adsbygoogle.adsbygoogle-noablate[data-vignette-loaded=true]\")\n",
    "                            # if len(ads_elems) > 0:\n",
    "                            #     ActionChains(driver).move_by_offset(5, 5).click().perform()\n",
    "                            #     time.sleep(5)\n",
    "                            url2 = f'{url}&page={i}'\n",
    "                            page = requests.get(url2)\n",
    "                            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "                            all_comments = soup.find_all(\"div\", attrs={\"class\":\"postmessage-content t_msgfont\"})\n",
    "                            comment_date = soup.find_all(\"div\", attrs={\"class\":\"post-date\"})\n",
    "                            for c in all_comments:\n",
    "                                if c.find(\"span\") == None:\n",
    "                                    data[\"Comments\"].append(\"NA\")\n",
    "                                    Topic_title = soup.find(\"span\", attrs={\"class\":\"topbar_tid\"}).text\n",
    "                                    data[\"Topic\"].append(Topic_title)\n",
    "                                elif c.find(\"span\").find(\"div\", attrs={\"class\":\"quote\"}) != None:\n",
    "                                    comment = c.find(\"span\")\n",
    "                                    unwanted = comment.find(\"div\", attrs={\"class\":\"quote\"})\n",
    "                                    unwanted.extract()\n",
    "                                    Topic_title = soup.find(\"span\", attrs={\"class\":\"topbar_tid\"}).text\n",
    "                                    data[\"Topic\"].append(Topic_title)\n",
    "                                    data[\"Comments\"].append(comment.text)\n",
    "                                elif c.find(\"span\").find(\"div\", attrs={\"class\": \"quote\"}) == None:\n",
    "                                    comment = c.find(\"span\").text\n",
    "                                    Topic_title = soup.find(\"span\", attrs={\"class\":\"topbar_tid\"}).text\n",
    "                                    data[\"Topic\"].append(Topic_title)\n",
    "                                    data[\"Comments\"].append(comment)\n",
    "                            for d in comment_date:\n",
    "                                data[\"Date\"].append(d.text)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "598b1d62-b830-4f95-b15d-43c94157ec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>美股跌幅收窄，道指，標普5連跌，穿20天線。納指倒升。VIX也跌。\\r\\n【儲局官員】沃勒、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>大陸數據確實不太安全</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>真係揾黎搞。阿里已經搖搖欲墜，再搞多幾野，咩信心都散......\\n\\n真係唔知諗乜。\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>睇黎阿爺要全方面打阿里</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>阿爺放過阿里啦，大國小氣小家到咁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13696</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌</td>\n",
       "      <td>你阿爺同俄佬玩自閉，鬥衰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13697</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌</td>\n",
       "      <td>mola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13698</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>NDX put: 10436</td>\n",
       "      <td>美國都未跌完\\r\\n彈下係最後逃生門 《香港討論區》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13699</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>NDX put: 10436</td>\n",
       "      <td>美股只有一個方向</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13700</th>\n",
       "      <td>\\n\\n                                          ...</td>\n",
       "      <td>NDX put: 10436</td>\n",
       "      <td>又來</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13701 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Date  \\\n",
       "0      \\n\\n                                          ...   \n",
       "1      \\n\\n                                          ...   \n",
       "2      \\n\\n                                          ...   \n",
       "3      \\n\\n                                          ...   \n",
       "4      \\n\\n                                          ...   \n",
       "...                                                  ...   \n",
       "13696  \\n\\n                                          ...   \n",
       "13697  \\n\\n                                          ...   \n",
       "13698  \\n\\n                                          ...   \n",
       "13699  \\n\\n                                          ...   \n",
       "13700  \\n\\n                                          ...   \n",
       "\n",
       "                                          Topic  \\\n",
       "0      美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "1      美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "2      美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "3      美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "4      美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "...                                         ...   \n",
       "13696               《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌   \n",
       "13697               《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌   \n",
       "13698                            NDX put: 10436   \n",
       "13699                            NDX put: 10436   \n",
       "13700                            NDX put: 10436   \n",
       "\n",
       "                                                Comments  \n",
       "0      美股跌幅收窄，道指，標普5連跌，穿20天線。納指倒升。VIX也跌。\\r\\n【儲局官員】沃勒、...  \n",
       "1                                             大陸數據確實不太安全  \n",
       "2      真係揾黎搞。阿里已經搖搖欲墜，再搞多幾野，咩信心都散......\\n\\n真係唔知諗乜。\\n\\...  \n",
       "3                                            睇黎阿爺要全方面打阿里  \n",
       "4                                       阿爺放過阿里啦，大國小氣小家到咁  \n",
       "...                                                  ...  \n",
       "13696                                       你阿爺同俄佬玩自閉，鬥衰  \n",
       "13697                                               mola  \n",
       "13698                         美國都未跌完\\r\\n彈下係最後逃生門 《香港討論區》  \n",
       "13699                                           美股只有一個方向  \n",
       "13700                                                 又來  \n",
       "\n",
       "[13701 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data1 = data.copy()\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a68e479f-6065-48c7-a058-1eccb3c35853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_transform(row):\n",
    "    return row.split(\"\\n\")[3].split(\" \")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "id": "5e2f8824-b2d3-4ed6-b693-dc4a05be451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data1[\"Comments\"])):\n",
    "#     if \"發表\" in data1[\"Comments\"][i]:\n",
    "#         data1[\"Comments\"][i] = ' '.join(data1[\"Comments\"][i].split(\"\\n\")[1:])\n",
    "#     else:\n",
    "#         data1[\"Comments\"][i] = data1[\"Comments\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "516b593f-c00e-48ea-9945-9b50435f8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[\"Date\"] = data1[\"Date\"].apply(date_transform)\n",
    "data1[\"Date\"] = pd.to_datetime(data1[\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a6c7d35-b53d-4c97-a358-58c30133c645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>美股跌幅收窄，道指，標普5連跌，穿20天線。納指倒升。VIX也跌。\\r\\n【儲局官員】沃勒、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>大陸數據確實不太安全</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>真係揾黎搞。阿里已經搖搖欲墜，再搞多幾野，咩信心都散......\\n\\n真係唔知諗乜。\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>睇黎阿爺要全方面打阿里</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-15</th>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>阿爺放過阿里啦，大國小氣小家到咁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-06</th>\n",
       "      <td>《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌</td>\n",
       "      <td>你阿爺同俄佬玩自閉，鬥衰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-06</th>\n",
       "      <td>《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌</td>\n",
       "      <td>mola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>NDX put: 10436</td>\n",
       "      <td>美國都未跌完\\r\\n彈下係最後逃生門 《香港討論區》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>NDX put: 10436</td>\n",
       "      <td>美股只有一個方向</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-06</th>\n",
       "      <td>NDX put: 10436</td>\n",
       "      <td>又來</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13701 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "Date                                                   \n",
       "2022-07-15  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "2022-07-15  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "2022-07-15  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "2022-07-15  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "2022-07-15  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "...                                              ...   \n",
       "2022-07-06               《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌   \n",
       "2022-07-06               《紐約郵報》：經濟衰退的恐慌籠罩華爾街，道琼斯指數暴跌   \n",
       "2022-06-29                            NDX put: 10436   \n",
       "2022-06-29                            NDX put: 10436   \n",
       "2022-07-06                            NDX put: 10436   \n",
       "\n",
       "                                                     Comments  \n",
       "Date                                                           \n",
       "2022-07-15  美股跌幅收窄，道指，標普5連跌，穿20天線。納指倒升。VIX也跌。\\r\\n【儲局官員】沃勒、...  \n",
       "2022-07-15                                         大陸數據確實不太安全  \n",
       "2022-07-15  真係揾黎搞。阿里已經搖搖欲墜，再搞多幾野，咩信心都散......\\n\\n真係唔知諗乜。\\n\\...  \n",
       "2022-07-15                                        睇黎阿爺要全方面打阿里  \n",
       "2022-07-15                                   阿爺放過阿里啦，大國小氣小家到咁  \n",
       "...                                                       ...  \n",
       "2022-07-06                                       你阿爺同俄佬玩自閉，鬥衰  \n",
       "2022-07-06                                               mola  \n",
       "2022-06-29                         美國都未跌完\\r\\n彈下係最後逃生門 《香港討論區》  \n",
       "2022-06-29                                           美股只有一個方向  \n",
       "2022-07-06                                                 又來  \n",
       "\n",
       "[13701 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1f3d064-b1a3-4c85-9c5c-2791810f2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[data1[\"Date\"] >= datetime.strptime(\"2022-07-10\", '%Y-%m-%d')].sort_values(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3453e68a-f772-41dc-8fd4-aacf0fbbf575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.drop(data1[data1[\"Date\"] == \"2022-07-17\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c043dfcd-4831-4567-a8e0-e37f703cc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(\"Discuss_comment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84e709b7-6865-455b-89da-8dfddda25e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11415</th>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>美國經濟降溫！摩根資管︰聯儲局或後悔加息過急</td>\n",
       "      <td>通脹…一直居高不下，反而先係最危險！\\n\\r\\n財長…及聯儲局長，都話會放棄市民，大手加息壓...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9579</th>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>加拿大經濟大簫條</td>\n",
       "      <td>Screenshot_20220710_192818.jpg (728.82 KB)2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>加拿大經濟大簫條</td>\n",
       "      <td>因為最近好多老尾和老墨過嚟大温隊cocaine，所以生意好旺，連帶啲陀地港女都好搶手，道友多...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9581</th>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>加拿大經濟大簫條</td>\n",
       "      <td>係大温呢喲真係超筍工，好多香港專業人仕，例如社工，財演都爭住做</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9582</th>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>加拿大經濟大簫條</td>\n",
       "      <td>中畀向威權統治\\r\\n那有民主</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>道指反彈658點   恆指會跟嗎？</td>\n",
       "      <td>https://news.tvb.com/tc/instant/ ... utm_mediu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>因為仲未踢走軟銀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>又要等阿爺出實招，再吾減息，放水，就搞吾掂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%</td>\n",
       "      <td>6月很多利好消息，抄高左，7月大陸就爆鑊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>通脹大爆發，巴菲特卻在加倉股票？！</td>\n",
       "      <td>傳市場話巴郡大舉持有西方石油</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                     Topic  \\\n",
       "11415 2022-07-10                    美國經濟降溫！摩根資管︰聯儲局或後悔加息過急   \n",
       "9579  2022-07-10                                  加拿大經濟大簫條   \n",
       "9580  2022-07-10                                  加拿大經濟大簫條   \n",
       "9581  2022-07-10                                  加拿大經濟大簫條   \n",
       "9582  2022-07-10                                  加拿大經濟大簫條   \n",
       "...          ...                                       ...   \n",
       "36    2022-07-16                         道指反彈658點   恆指會跟嗎？   \n",
       "35    2022-07-16  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "34    2022-07-16  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "32    2022-07-16  美期反彈；恒指IG試20400，金管局買入53.22億港元，阿里美股低港6.3%   \n",
       "1488  2022-07-16                         通脹大爆發，巴菲特卻在加倉股票？！   \n",
       "\n",
       "                                                Comments  \n",
       "11415  通脹…一直居高不下，反而先係最危險！\\n\\r\\n財長…及聯儲局長，都話會放棄市民，大手加息壓...  \n",
       "9579      Screenshot_20220710_192818.jpg (728.82 KB)2...  \n",
       "9580   因為最近好多老尾和老墨過嚟大温隊cocaine，所以生意好旺，連帶啲陀地港女都好搶手，道友多...  \n",
       "9581                     係大温呢喲真係超筍工，好多香港專業人仕，例如社工，財演都爭住做  \n",
       "9582                                     中畀向威權統治\\r\\n那有民主  \n",
       "...                                                  ...  \n",
       "36     https://news.tvb.com/tc/instant/ ... utm_mediu...  \n",
       "35                                              因為仲未踢走軟銀  \n",
       "34                                 又要等阿爺出實招，再吾減息，放水，就搞吾掂  \n",
       "32                                  6月很多利好消息，抄高左，7月大陸就爆鑊  \n",
       "1488                                      傳市場話巴郡大舉持有西方石油  \n",
       "\n",
       "[2022 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ea25b-603a-49d6-b4d4-263fca2867ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
